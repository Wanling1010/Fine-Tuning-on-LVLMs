{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At9UC5dHtso_"
      },
      "source": [
        "fine tuning llava on custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oGo2wPKq-tsv",
        "outputId": "7807072f-dcdd-4f1a-a8e4-3dabf06592f0"
      },
      "outputs": [],
      "source": [
        "# Install preprocessing libraries\n",
        "!pip install datasets\n",
        "!pip install --upgrade --force-reinstall Pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2ayTSH7D6-j",
        "outputId": "ab5d24f8-05ca-4b54-f4f7-73baa65e57f0"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "md62QztAmWLJ",
        "outputId": "c3019662-99e8-4945-dea7-034af3c1b6f9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import uuid\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def process_and_save(image_path, label, output_folder, subset_name):\n",
        "    try:\n",
        "        subset_folder = os.path.join(output_folder, subset_name)\n",
        "        image_subfolder = os.path.join(output_folder, 'images')\n",
        "\n",
        "        if not os.path.exists(image_subfolder):\n",
        "            os.makedirs(image_subfolder)\n",
        "        if not os.path.exists(subset_folder):\n",
        "            os.makedirs(subset_folder)\n",
        "\n",
        "        unique_id = str(uuid.uuid4())\n",
        "\n",
        "        if not os.path.exists(image_path):\n",
        "            print(f\"File does not exist: {image_path}\")\n",
        "            return None\n",
        "\n",
        "        _, file_extension = os.path.splitext(image_path)\n",
        "\n",
        "        try:\n",
        "            img = cv2.imread(image_path)\n",
        "            if img is None:\n",
        "                print(f\"OpenCV cannot read image file: {image_path}\")\n",
        "                return None\n",
        "\n",
        "            new_image_path = os.path.join(image_subfolder, f\"{unique_id}{file_extension.lower()}\")\n",
        "            cv2.imwrite(new_image_path, img)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image {image_path}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "        json_data = {\n",
        "            \"id\": unique_id,\n",
        "            \"image\": f\"{unique_id}{file_extension.lower()}\",\n",
        "            \"conversations\": [\n",
        "                {\n",
        "                    \"from\": \"human\",\n",
        "                    \"value\": \"Analyze this chest X-ray image and determine the type of condition shown.\"\n",
        "                },\n",
        "                {\n",
        "                    \"from\": \"gpt\",\n",
        "                    \"value\": f\"Based on the chest X-ray image, the condition shown is {label}.\"\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        return json_data\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error processing {image_path}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def process_dataset(data_folder, output_folder):\n",
        "    json_data_list = {'train': [], 'test': []}\n",
        "    allowed_extensions = {'.jpeg', '.jpg', '.png'}\n",
        "    labels = ['Covid', 'Normal', 'Viral Pneumonia']\n",
        "\n",
        "    for subset in ['train', 'test']:\n",
        "        subset_path = os.path.join(data_folder, subset)\n",
        "        for label in labels:\n",
        "            label_path = os.path.join(subset_path, label)\n",
        "            if not os.path.exists(label_path):\n",
        "                print(f\"Warning: Path does not exist: {label_path}\")\n",
        "                continue\n",
        "            for image_name in os.listdir(label_path):\n",
        "                if any(image_name.lower().endswith(ext) for ext in allowed_extensions):\n",
        "                    image_path = os.path.join(label_path, image_name)\n",
        "                    print(f\"Processing file: {image_path}\")\n",
        "                    print(f\"File size: {os.path.getsize(image_path)} bytes\")\n",
        "                    json_data = process_and_save(image_path, label, output_folder, subset)\n",
        "                    if json_data is not None:\n",
        "                        json_data_list[subset].append(json_data)\n",
        "\n",
        "    for subset in ['train', 'test']:\n",
        "        json_output_path = os.path.join(output_folder, subset, 'dataset.json')\n",
        "        with open(json_output_path, 'w') as json_file:\n",
        "            json.dump(json_data_list[subset], json_file, indent=4)\n",
        "\n",
        "# Usage\n",
        "data_folder = '/content/drive/MyDrive/AnomalyGPT/Covid19-dataset'\n",
        "output_folder = '/content/drive/MyDrive/AnomalyGPT/output'\n",
        "process_dataset(data_folder, output_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJzymdpeuOf5",
        "outputId": "60278108-4e95-4c51-e8a3-06c355ccc40a"
      },
      "outputs": [],
      "source": [
        "# The pip install -e . lets us install the repository in editable mode\n",
        "!git clone https://github.com/haotian-liu/LLaVA.git\n",
        "!cd LLaVA && pip install --upgrade pip && pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gN-a_nGRvYaJ",
        "outputId": "818ece80-6e6f-4a02-9fba-6380b2b03b45"
      },
      "outputs": [],
      "source": [
        "!cd LLaVA && pip install -e \".[train]\"\n",
        "!pip install flash-attn --no-build-isolation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eid1n9qrwMe4",
        "outputId": "19170b7e-91c0-460b-b54f-0106451cdf77"
      },
      "outputs": [],
      "source": [
        "!pip install deepspeed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4puXWHfkwOY0",
        "outputId": "2ceb3dd0-5a4a-4088-ceb8-90ee71d99700"
      },
      "outputs": [],
      "source": [
        "!pip install wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "em-IJIqzwObi",
        "outputId": "6095bb33-325c-4ba9-d21f-459f1e2b6227"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-ELMP8WxJWc",
        "outputId": "6b7d14b0-18c0-442e-d0da-059348cc3201"
      },
      "outputs": [],
      "source": [
        "!deepspeed LLaVA/llava/train/train_mem.py \\\n",
        "    --lora_enable True --lora_r 128 --lora_alpha 256 --mm_projector_lr 2e-5 \\\n",
        "    --deepspeed LLaVA/scripts/zero3.json \\\n",
        "    --model_name_or_path liuhaotian/llava-v1.5-13b \\\n",
        "    --version v1 \\\n",
        "    --data_path /content/drive/MyDrive/AnomalyGPT/output/train/dataset.json \\\n",
        "    --image_folder /content/drive/MyDrive/AnomalyGPT/output/images \\\n",
        "    --vision_tower openai/clip-vit-large-patch14-336 \\\n",
        "    --mm_projector_type mlp2x_gelu \\\n",
        "    --mm_vision_select_layer -2 \\\n",
        "    --mm_use_im_start_end False \\\n",
        "    --mm_use_im_patch_token False \\\n",
        "    --image_aspect_ratio pad \\\n",
        "    --group_by_modality_length True \\\n",
        "    --bf16 True \\\n",
        "    --output_dir /content/drive/MyDrive/AnomalyGPT/checkpoints/llava-v1.5-13b-task-lora \\\n",
        "    --num_train_epochs 1 \\\n",
        "    --per_device_train_batch_size 16 \\\n",
        "    --per_device_eval_batch_size 4 \\\n",
        "    --gradient_accumulation_steps 1 \\\n",
        "    --evaluation_strategy \"no\" \\\n",
        "    --save_strategy \"steps\" \\\n",
        "    --save_steps 50000 \\\n",
        "    --save_total_limit 1 \\\n",
        "    --learning_rate 2e-4 \\\n",
        "    --weight_decay 0. \\\n",
        "    --warmup_ratio 0.03 \\\n",
        "    --lr_scheduler_type \"cosine\" \\\n",
        "    --logging_steps 1 \\\n",
        "    --tf32 True \\\n",
        "    --model_max_length 2048 \\\n",
        "    --gradient_checkpointing True \\\n",
        "    --dataloader_num_workers 4 \\\n",
        "    --lazy_preprocess True \\\n",
        "    --report_to wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bb8kcn8KxJZD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
