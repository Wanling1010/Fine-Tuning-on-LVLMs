{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets keras-tuner"
      ],
      "metadata": {
        "id": "gIYpIL98TWtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from kerastuner import RandomSearch\n",
        "from kerastuner.engine.hyperparameters import HyperParameters"
      ],
      "metadata": {
        "id": "Rg_WCNIdWdjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset from Hugging Face\n",
        "dataset = load_dataset(\"yuighj123/covid-19-classification\")\n",
        "\n",
        "def preprocess_data(examples):\n",
        "    images = []\n",
        "    for img in examples['image']:\n",
        "        # Convert to numpy array if it's not already\n",
        "        if not isinstance(img, np.ndarray):\n",
        "            img = np.array(img)\n",
        "\n",
        "        # Ensure 3D shape (height, width, channels)\n",
        "        if len(img.shape) == 2:\n",
        "            img = np.expand_dims(img, axis=-1)\n",
        "\n",
        "        # Ensure consistent data type\n",
        "        img = img.astype(np.float32) / 255.0  # Normalize to [0, 1]\n",
        "\n",
        "        images.append(img)\n",
        "\n",
        "    labels = examples['label']\n",
        "    return {'images': images, 'labels': labels}\n",
        "\n",
        "# Apply the preprocessing\n",
        "dataset = dataset.map(preprocess_data, batched=True, batch_size=32)\n",
        "\n",
        "# Split the dataset\n",
        "train_dataset = dataset['train'].shuffle(1000)\n",
        "test_dataset = dataset['test']"
      ],
      "metadata": {
        "id": "0Ur877QlKnG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the data\n",
        "def preprocess_data(example):\n",
        "    image = np.array(example['image'])  # Convert PIL Image to numpy array\n",
        "    image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0, 1]\n",
        "    return image, example['label']\n",
        "\n",
        "# Convert to TensorFlow dataset\n",
        "def create_tf_dataset(hf_dataset, batch_size=32):\n",
        "    tf_dataset = tf.data.Dataset.from_tensor_slices(hf_dataset)\n",
        "    tf_dataset = tf_dataset.map(preprocess_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    tf_dataset = tf_dataset.batch(batch_size)\n",
        "    return tf_dataset.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "JHfvsFc_d91r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train and test datasets\n",
        "train_dataset = create_tf_dataset(dataset['train'])\n",
        "test_dataset = create_tf_dataset(dataset['test'])"
      ],
      "metadata": {
        "id": "6RMHk6EReP2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an image data generator with augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Fit the data generator on the training data\n",
        "datagen.fit(x_train)\n"
      ],
      "metadata": {
        "id": "VtDe0dwMWaqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model-building function\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Conv2D(\n",
        "        filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=32),\n",
        "        kernel_size=hp.Choice('conv_1_kernel', values=[3, 5]),\n",
        "        activation='relu',\n",
        "        input_shape=(32, 32, 3)\n",
        "    ))\n",
        "    model.add(keras.layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    for i in range(hp.Int('n_conv_layers', 1, 3)):\n",
        "        model.add(keras.layers.Conv2D(\n",
        "            filters=hp.Int(f'conv_{i+2}_filter', min_value=32, max_value=128, step=32),\n",
        "            kernel_size=hp.Choice(f'conv_{i+2}_kernel', values=[3, 5]),\n",
        "            activation='relu'\n",
        "        ))\n",
        "        model.add(keras.layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(keras.layers.Flatten())\n",
        "    model.add(keras.layers.Dense(\n",
        "        units=hp.Int('dense_1_units', min_value=32, max_value=128, step=32),\n",
        "        activation='relu'\n",
        "    ))\n",
        "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(\n",
        "            hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "        ),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "N3xCZSWwTVqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the tuner\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=1,\n",
        "    directory='my_dir',\n",
        "    project_name='covid19_tuning'\n",
        ")\n",
        "\n",
        "# Perform hyperparameter search\n",
        "tuner.search(train_dataset, epochs=10, validation_data=test_dataset)\n",
        "\n",
        "# Get the best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Train the best model\n",
        "history = best_model.fit(train_dataset, epochs=50, validation_data=test_dataset)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = best_model.evaluate(test_dataset)\n",
        "print(f'Test accuracy: {test_acc:.3f}')"
      ],
      "metadata": {
        "id": "hT9ihdJfTL0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot accuracy curves\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Zi7SLff5TK92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the code below if the above code takes too long to run"
      ],
      "metadata": {
        "id": "EKNZA5H5f0DD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "LmYulbTWgznY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mount your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "QR72FhQOgSVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TestDataGenerator = ImageDataGenerator(rescale = 1/255)\n",
        "\n",
        "TrainDataGenerator = ImageDataGenerator(rescale = 1/255,\n",
        "                                        zoom_range = 0.15,\n",
        "                                        rotation_range = 12,\n",
        "                                        width_shift_range=0.05,\n",
        "                                        height_shift_range=0.05)"
      ],
      "metadata": {
        "id": "RlWIR4l2fwg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = '/content/drive/MyDrive/AnomalyGPT/Covid19-dataset/train'\n",
        "test_data_dir = '/content/drive/MyDrive/AnomalyGPT/Covid19-dataset/test'\n",
        "\n",
        "train_data = TestDataGenerator.flow_from_directory(train_data_dir,\n",
        "                                                target_size = (512, 512),\n",
        "                                                batch_size = 16,\n",
        "                                                class_mode = \"categorical\",\n",
        "                                                color_mode = 'grayscale')\n",
        "\n",
        "test_data = TrainDataGenerator.flow_from_directory(test_data_dir,\n",
        "                                                target_size = (512, 512),\n",
        "                                                batch_size = 2,\n",
        "                                                class_mode = \"categorical\",\n",
        "                                                color_mode = 'grayscale')"
      ],
      "metadata": {
        "id": "xDZJxQRmf1dZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "#Input layer\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.Input(shape=(512, 512, 1)))\n",
        "\n",
        "model.add(layers.Conv2D(filters = 16,\n",
        "                kernel_size = (5, 5),\n",
        "                activation = \"relu\"))\n",
        "\n",
        "model.add(layers.MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(filters = 16,\n",
        "                kernel_size = (3, 3),\n",
        "                activation = \"relu\"))\n",
        "\n",
        "model.add(layers.MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(filters = 16,\n",
        "                kernel_size = (3, 3),\n",
        "                activation = \"relu\"))\n",
        "\n",
        "model.add(layers.MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(4, 3, strides=1, activation=\"relu\"))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(16, activation = 'relu'))\n",
        "model.add(layers.Dense(16, activation = 'relu'))\n",
        "#Output layer\n",
        "model.add(layers.Dense(3, activation = \"softmax\"))"
      ],
      "metadata": {
        "id": "AQig85Rkgqvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "model.compile(optimizer = \"Adam\",\n",
        "             loss = \"categorical_crossentropy\",\n",
        "             metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "AXHAHHIkg2Cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_data, epochs = 10, verbose = 1, validation_data = test_data, validation_split=0.1)"
      ],
      "metadata": {
        "id": "FArqRUuEg53m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot accuracy curves\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jxF-dtyyhDbs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}